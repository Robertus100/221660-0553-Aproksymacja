{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wpowadzenie do deep learning w bibliotece Flux.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przykład"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby w  zrozumieć sposób pracy z Fluxem warto rozpatrzeć prosty przykład. Zajmiemy się przetwarzaniem języka naturalnego - zbudujemy model zdolny do generowania składnej wypowiedzi w języku polskim.\n",
    "\n",
    "Wyjściowe założenie jest takie, że wytrenujemy sieć neuronową, która będzie estymowała prawdopodobieństwo wystąpienia danego znaku w ciągu na podstawie poprzedzających go znaków w sekwencji ([<b>Character-Level Language Model</b>](http://karpathy.github.io/2015/05/21/rnn-effectiveness/))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbiórem na którym będziemy pracowali jest <i>W poszukiwaniu straconego czasu</i> Marcela Prousta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](https://upload.wikimedia.org/wikipedia/commons/b/b8/Marcel_Proust_1895.jpg)](https://pl.wikipedia.org/wiki/Marcel_Proust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">(...) matka widząc, że mi jest zimno, namówiła mnie, abym się napił wbrew zwyczajowi trochę herbaty. Odmówiłem zrazu; potem, nie wiem czemu, namyśliłem się. Posłała po owe krótkie i pulchne ciasteczka zwane magdalenkami, które wyglądają jak odlane w prążkowanej skorupie muszli. I niebawem (...) machinalnie podniosłem do ust łyżeczkę herbaty, w której rozmoczyłem kawałek magdalenki. Ale w tej samej chwili, kiedy łyk pomieszany z okruchami ciasta dotknął mego podniebienia, zadrżałem, czując, że się we mnie dzieje coś niezwykłego. Owładnęła mną rozkoszna słodycz (...). Sprawiła, że w jednej chwili koleje życia stały mi się obojętne, klęski jako błahe, krótkość złudna (...). Cofam się myślą do chwili, w której wypiłem pierwszą łyżeczkę herbaty (...). I nagle wspomnienie zjawiło mi się. Ten smak to była magdalenka cioci Leonii.(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zanim jednak zaczniemy wprowadźmy odrobinę teorii stojącej za tym zagadnieniem:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rekurencyjne sieci neuronowe (Recurrent neural networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Charakterystyczną cechą tego typu sieci jest to, że pozwalają one na istnienie wewnątrz grafu cykli skierowanych.\n",
    "- Oznacza to, że informacja wewnątrz takiej sieci nie musi płynąć tylko w jednym kierunku - neurony leżące na tej samej warstwie także mogą przesyłać sobie wzajemnie dane:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](http://karpathy.github.io/assets/rnn/diags.jpeg)](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dzięki tej właściwości RNN doskonale nadają się do budowy interesującego nas modelu: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](http://karpathy.github.io/assets/rnn/charseq.jpeg)](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Long short-term memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Problemem na który można natrafić w przypadku korzystania z RNN jest pamięć takiej sieci. Gdy odległość pomiędzy aktualnym a poprzedzającymi go węzłami, które niosą za sobą kluczową informację jest niewielka, sieć jest w stanie efektywnie je wykorzystać:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-shorttermdepdencies.png)](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Problem się pojawia gdy ta odległość jest duża - wtedy kluczowe informacje po prostu znikają w szumie:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-longtermdependencies.png)](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wtedy też, warto zastosować sieć LSTM, która ze względu na swoją architekturę jest w stanie odpowiednio filtrować informację i wykorzystawać je nawet wtedy, gdy ich źródło jest znacznie oddalone od aktualnego neuronu:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png)](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Przejdźmy teraz do implementowania modelu za pomocą Fluxa:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux: onehot, argmax, chunk, batchseq, throttle, crossentropy\n",
    "using StatsBase: wsample\n",
    "using Base.Iterators: partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pierwszym krokiem jest oczywiście odpowiednie przygotowanie danych na których będziemy pracowali:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = collect(read(\"w_poszukiwaniu.txt\",String));\n",
    "alphabet = [unique(text)..., '_'];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Następnie kodujemy zmienne jakościowe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = map(ch -> onehot(ch, alphabet), text);\n",
    "stop = onehot('_', alphabet);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = length(alphabet);\n",
    "seqlen = 100;\n",
    "batch_size = 32;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = collect(partition(batchseq(chunk(text, batch_size), stop), seqlen));\n",
    "Ys = collect(partition(batchseq(chunk(text[2:end], batch_size), stop), seqlen));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = chunk(\"ala ma kota\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = batchseq(q, '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in partition(w, 2)\n",
    "   println(i)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect(partition(w,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect(partition(batchseq(chunk(\"ala ma kota\"[2:end], 3), '_'),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#12 (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Chain(\n",
    "    LSTM(N, 128),\n",
    "    Dropout(0.5), \n",
    "    LSTM(128, 128),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, N),\n",
    "    softmax)\n",
    "\n",
    "function loss(xs, ys)\n",
    "  l = sum(crossentropy.(m.(xs), ys))\n",
    "  Flux.truncate!(m)\n",
    "  return l\n",
    "end\n",
    "\n",
    "opt = ADAM(0.001)\n",
    "\n",
    "\n",
    "function sample(m, alphabet, len; temp = 1)\n",
    "  Flux.reset!(m)\n",
    "  buf = IOBuffer()\n",
    "  c = rand(alphabet)\n",
    "  for i = 1:len\n",
    "    write(buf, c)\n",
    "    c = wsample(alphabet, m(onehot(c, alphabet)).data)\n",
    "  end\n",
    "  return String(take!(buf))\n",
    "end\n",
    "\n",
    "evalcb = () -> @show loss(Xs[5], Ys[5])\n",
    "\n",
    "#evalcb = function ()\n",
    "#    @show loss(Xs[5], Ys[5])\n",
    "#    println(sample(deepcopy(m), alphabet, 100))\n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 1\n",
      "└ @ Main C:\\Users\\p\\.julia\\packages\\Flux\\zNlBL\\src\\optimise\\train.jl:105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(Xs[5], Ys[5]) = 478.4657f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 332.77264f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 292.60413f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 272.03925f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 261.71442f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 256.8383f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 252.2395f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 248.2264f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 243.43987f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 240.7371f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 237.26335f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 235.19301f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 234.18915f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 233.12976f0 (tracked)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 2\n",
      "└ @ Main C:\\Users\\p\\.julia\\packages\\Flux\\zNlBL\\src\\optimise\\train.jl:105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(Xs[5], Ys[5]) = 230.86375f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 229.00516f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 228.54037f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 225.23131f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 225.33601f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 224.24614f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 221.65182f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 220.89214f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 219.32072f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 216.43709f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 216.82336f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 215.46017f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 214.70876f0 (tracked)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 3\n",
      "└ @ Main C:\\Users\\p\\.julia\\packages\\Flux\\zNlBL\\src\\optimise\\train.jl:105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(Xs[5], Ys[5]) = 213.86687f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 211.24521f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 209.4972f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 208.56644f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 209.90005f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 206.6048f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 206.75063f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 206.10915f0 (tracked)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 4\n",
      "└ @ Main C:\\Users\\p\\.julia\\packages\\Flux\\zNlBL\\src\\optimise\\train.jl:105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(Xs[5], Ys[5]) = 204.05675f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 203.73071f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 203.47665f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 201.3106f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 201.97388f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 200.84041f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 201.17735f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 199.21379f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 199.85109f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 200.21931f0 (tracked)\n",
      "loss(Xs[5], Ys[5]) = 201.95644f0 (tracked)\n"
     ]
    }
   ],
   "source": [
    "Flux.@epochs 4 Flux.train!(loss, params(m), zip(Xs, Ys), opt,\n",
    "cb = throttle(evalcb, 240))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
