{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Flux, Flux.Data.MNIST\n",
    "using Flux: throttle, params\n",
    "using Juno: @progress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data, binarise it, and partition into mini-batches of M.\n",
    "X = float.(hcat(vec.(MNIST.images())...)) .> 0.5\n",
    "N, M = size(X, 2), 100\n",
    "data = [X[:,i] for i in Iterators.partition(1:N,M)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Po tym jak wyjaśniliśmy sobie czym jest zwykły autoencoder możemy przejść do opisania jego bardziej zaawansowanej (i ciekawszej) formy - Variational Autoencodera (VAE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Klasyczny autoencoder pozwala nam na zakodowanie danych (najczęściej obrazu) w formie wektora zmiennych ukrytych <i>(latent variables)</i>:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](http://kvfrans.com/content/images/2016/08/autoenc.jpg)](http://kvfrans.com/variational-autoencoders-explained/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taki model pozwala na całkiem efektywną kompresję wejściowych danych. Jednak co należy zrobić gdy chcielibyśmy generować noweobrazy na podstawie danych wejściowych a nie jedynie je odtwarzać?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variational Autoencoder jest klasą modeli, która na to pozwala. Intuicja  za nimi stojąca jest prosta, sieć dekodująca zamiast odtwarzać obraz w skali 1:1 dodaje do nich pewną losowość, dzięki której wyjściowy obraz jest nieznacznie zmieniony w stosunku do obrazu wejściowego."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otrzymanie tej losowości jest możliwe dzięki wygenerowaniu przez sieć kodującą nie tyle wektora zmiennych ukrytych, co wektora średnich i odchyleń standardowych zmiennych ukrytych z których następnie losowane są zmienne ukryte wykorzystane przez sieć dekodującą:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](http://kvfrans.com/content/images/2016/08/vae.jpg)](http://kvfrans.com/variational-autoencoders-explained/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdefiniujmy taki model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################# Define Model #################################\n",
    "\n",
    "# Latent dimensionality, # hidden units.\n",
    "Dz, Dh = 5, 500\n",
    "\n",
    "# Components of recognition model / \"encoder\" MLP.\n",
    "A, μ, logσ = Dense(28^2, Dh, tanh), Dense(Dh, Dz), Dense(Dh, Dz)\n",
    "g(X) = (h = A(X); (μ(h), logσ(h)))\n",
    "z(μ, logσ) = μ + exp(logσ) * randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generative model / \"decoder\" MLP.\n",
    "f = Chain(Dense(Dz, Dh, tanh), Dense(Dh, 28^2, σ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Przejdźmy teraz do zdefiniowania funkcji straty i procesu uczenia się modelu. Zacznijmy od prostej, technicznej definicji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################### Define ways of doing things with the model. #######################\n",
    "# Extend distributions slightly to have a numerically stable logpdf for `p` close to 1 or 0.\n",
    "using Distributions\n",
    "import Distributions: logpdf\n",
    "logpdf(b::Bernoulli, y::Bool) = y * log(b.p + eps()) + (1 - y) * log(1 - b.p + eps())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i zastanówmy jak powinna wyglądać funkcja straty tego modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KL-divergence between approximation posterior and N(0, 1) prior.\n",
    "kl_q_p(μ, logσ) = 0.5 * sum(exp.(2 .* logσ) + μ.^2 - 1 .+ logσ.^2)\n",
    "\n",
    "# logp(x|z) - conditional probability of data given latents.\n",
    "logp_x_z(x, z) = sum(logpdf.(Bernoulli.(f(z)), x))\n",
    "\n",
    "# Monte Carlo estimator of mean ELBO using M samples.\n",
    "L̄(X) = ((μ̂, logσ̂) = g(X); (logp_x_z(X, z.(μ̂, logσ̂)) - kl_q_p(μ̂, logσ̂)) / M)\n",
    "\n",
    "loss(X) = -L̄(X) + 0.01 * sum(x->sum(x.^2), params(f))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wiedząc jak powinien wyglądać model możemy zacząć go uczyć:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "################################# Learn Parameters ##############################\n",
    "\n",
    "evalcb = throttle(() -> @show(-L̄(X[:, rand(1:N, M)])), 30)\n",
    "opt = ADAM(params(A, μ, logσ, f))\n",
    "@progress for i = 1:20\n",
    "  info(\"Epoch $i\")\n",
    "  Flux.train!(loss, zip(data), opt, cb=evalcb)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I na koniec sprawdzić czy sieć poprawnie generuje obrazy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################# Sample Output ##############################\n",
    "\n",
    "using Images\n",
    "\n",
    "# Sample from the learned model.\n",
    "modelsample() = rand.(Bernoulli.(f(z.(zeros(Dz), zeros(Dz)))))\n",
    "\n",
    "\n",
    "img(x) = Gray.(reshape(x, 28, 28))\n",
    "\n",
    "sample = hcat(img.([modelsample() for i = 1:10])...)\n",
    "save(\"sample.png\", sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
